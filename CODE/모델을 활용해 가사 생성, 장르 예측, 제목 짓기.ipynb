{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOu/pVM16F5+KxKIGACnfAu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 구글 드라이브 마운트"],"metadata":{"id":"0bY9eE4f6ccQ"}},{"cell_type":"code","source":["# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 구글 드라이브 경로 설정\n","%cd /content/drive/MyDrive/텍스트 프로젝트\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Yglz_Coa6c5P","executionInfo":{"status":"ok","timestamp":1696934675985,"user_tz":-540,"elapsed":16220,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"04cee3f3-810f-4370-af7c-32281fb8590f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/텍스트 프로젝트\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/텍스트 프로젝트'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["### 라이브러리 설치"],"metadata":{"id":"pNwD8F1S46Sv"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqvdD9u533Sv","executionInfo":{"status":"ok","timestamp":1696934687621,"user_tz":-540,"elapsed":11641,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"d6861067-9db5-4156-df81-2962e0f68b81"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"]}]},{"cell_type":"markdown","source":["### 라이브러리 불러오기"],"metadata":{"id":"m-4OwxnP6Foo"}},{"cell_type":"code","source":["import torch\n","from transformers import AdamW, AutoConfig, GPT2LMHeadModel, PreTrainedTokenizerFast\n","from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n"],"metadata":{"id":"nY7V8Mfy6HCv","executionInfo":{"status":"ok","timestamp":1696935446423,"user_tz":-540,"elapsed":6,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### 가사 생성"],"metadata":{"id":"a9uxsCGZ4Yqw"}},{"cell_type":"code","source":["device = torch.device(\"cpu\")\n","\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","                bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","                pad_token='<pad>', mask_token='<mask>')\n","\n","\n","# 저장한 모델 불러오기\n","load_data = torch.load(\"model_kogpt2/kogpt2_fine-tunning_51.pt\", map_location=torch.device(\"cpu\"))\n","\n","# 모델 로드\n","config = AutoConfig.from_pretrained(\n","            \"gpt2\",\n","            vocab_size=len(tokenizer),\n","            bos_token_id = tokenizer.bos_token_id,\n","            eos_token_id = tokenizer.eos_token_id,\n","        )\n","\n","model = GPT2LMHeadModel(config).to(device)\n","model.load_state_dict(load_data['model'])\n","\n","# 옵티마이저 로드\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8)\n","optimizer.load_state_dict(load_data['optimizer'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Ef9SaTp3goP","executionInfo":{"status":"ok","timestamp":1696937247944,"user_tz":-540,"elapsed":11837,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"357048f1-0c62-4df2-d531-acf6b41382cf"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def generate(keyword):\n","    input_ids = tokenizer.encode(keyword, return_tensors='pt')\n","    input_ids = input_ids.to(device)\n","    gen_ids = model.generate(input_ids,\n","                        max_length=128,\n","                        repetition_penalty=2.0,\n","                        pad_token_id=tokenizer.pad_token_id,\n","                        eos_token_id=tokenizer.eos_token_id,\n","                        bos_token_id=tokenizer.bos_token_id,\n","                        use_cache=True)\n","    generated = tokenizer.decode(gen_ids[0])\n","    return generated"],"metadata":{"id":"JSwvrqRG3eeQ","executionInfo":{"status":"ok","timestamp":1696937247945,"user_tz":-540,"elapsed":4,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["keywords = ['사랑', '그대', '생각', '사람']\n","\n","lyrics_lst = []\n","\n","for keyword in keywords:\n","    #keyword = keyword.to(device)\n","    gen = generate(keyword)\n","    gen_print = gen.split('\\n')[0:2][0]\n","    lyrics_lst.append(gen_print)\n","    print(f\"{keyword} : {gen_print}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBaEz8eeVvQ-","executionInfo":{"status":"ok","timestamp":1696937266890,"user_tz":-540,"elapsed":18947,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"5d694a82-d792-4788-a4a4-1b9ea1879f8d"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["사랑 : 사랑이별가요 괜찮아 질거야 이별없는 거니까그 많은 약속들은 어제와 같은 선물로점쳐지고 떠나가는 게제 뻔한 일이죠하지만 내 진심만은 알아줬으면 해요한마디 말이면 충분해나 혹시 그대 생각 나겠지만사랑에 바쁜 나를 피해서저별을 준비했단걸사랑이 중요하진 않아잘 안돼 우리가 왜 이렇게 외로운지난 몰라 당신만을 위해서만 기도하고바랬던 사랑이 필요했다면다른 건 아무 의미없어나는 그대를 알기 때문에살아가면서 한번도 느껴지지 않던자존심을 다 버렸\n","그대 : 그대 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던 사랑을그대 떠나 가던 밤모두 잊으라시며마지막 인사를 나 하염없이 하던 그 약속간절한 내 마음약속 하지 않았네기다리는 나를 모르시나요행여나 찾아 올까봐 혼자 애태우는 이 마음은어느샌가 거리길가에 스쳐가는언제나 익숙한 목소리작은 두 글자로우리 이름을 써놓고몇 밤을 울다 잠든 다정히 창밖 바라보기만 보며 말하던 나이별을 두고이제는 떠난 사람무엇인가 빈 추억인거죠사랑했던 우리야 이별\n","생각 : 생각도 못했던 말내겐 사랑이란 걸 몰랐던거야이제 우리 같은 시간 속을 남처럼그렇게 걸어왔어요생각보다 오래 된 것 같아요한 번쯤은 나를 떠나줄 것만 같아서난 정말 쉬지 않았죠사랑했던 날 늘 붙잡고떠나지 말라고흘러댔었던 내 맘을하얗게 물들인 밤하늘에 그려보아직도 나는 서 있을까더는 네 모습 볼 수 없겠지만아직 너를 위해 준비해둔 말이제는 말해볼 만하지 못한 나의 마음나는 너무 아파다시 널 보낼 자신이 없어초라했나봐 넌 내게 언제나 이런 얘기를 했었지어\n","사람 : 사람 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던그 이름 난사랑하네 다정한 그 목소리로노래 불러요잊어 주세요가끔은 그리운 사람과해맑고 웃으며내게 편지를 쓰나봐오늘 밤도 널 그리워하다못 잊어서 돌아오질 못해이렇게 나는 울었네이별 후 더 힘들다 맘 이젠 추억아직 허기진 조금 남아있우리 다시 만나면감사예전 그대 모습 그대로 일거야안녕다시 또 우리 만날 때까지몇 번이고 말해줘나의 목소리 너의 미소다가올 이별마저 안 될 만큼너를 많이 좋아\n"]}]},{"cell_type":"code","source":["lyrics_lst"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DL2XVYNGWDJa","executionInfo":{"status":"ok","timestamp":1696937297363,"user_tz":-540,"elapsed":7,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"7f14f19e-2224-49f4-eb0b-2a7a5a9db1b3"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['사랑이별가요 괜찮아 질거야 이별없는 거니까그 많은 약속들은 어제와 같은 선물로점쳐지고 떠나가는 게제 뻔한 일이죠하지만 내 진심만은 알아줬으면 해요한마디 말이면 충분해나 혹시 그대 생각 나겠지만사랑에 바쁜 나를 피해서저별을 준비했단걸사랑이 중요하진 않아잘 안돼 우리가 왜 이렇게 외로운지난 몰라 당신만을 위해서만 기도하고바랬던 사랑이 필요했다면다른 건 아무 의미없어나는 그대를 알기 때문에살아가면서 한번도 느껴지지 않던자존심을 다 버렸',\n"," '그대 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던 사랑을그대 떠나 가던 밤모두 잊으라시며마지막 인사를 나 하염없이 하던 그 약속간절한 내 마음약속 하지 않았네기다리는 나를 모르시나요행여나 찾아 올까봐 혼자 애태우는 이 마음은어느샌가 거리길가에 스쳐가는언제나 익숙한 목소리작은 두 글자로우리 이름을 써놓고몇 밤을 울다 잠든 다정히 창밖 바라보기만 보며 말하던 나이별을 두고이제는 떠난 사람무엇인가 빈 추억인거죠사랑했던 우리야 이별',\n"," '생각도 못했던 말내겐 사랑이란 걸 몰랐던거야이제 우리 같은 시간 속을 남처럼그렇게 걸어왔어요생각보다 오래 된 것 같아요한 번쯤은 나를 떠나줄 것만 같아서난 정말 쉬지 않았죠사랑했던 날 늘 붙잡고떠나지 말라고흘러댔었던 내 맘을하얗게 물들인 밤하늘에 그려보아직도 나는 서 있을까더는 네 모습 볼 수 없겠지만아직 너를 위해 준비해둔 말이제는 말해볼 만하지 못한 나의 마음나는 너무 아파다시 널 보낼 자신이 없어초라했나봐 넌 내게 언제나 이런 얘기를 했었지어',\n"," '사람 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던그 이름 난사랑하네 다정한 그 목소리로노래 불러요잊어 주세요가끔은 그리운 사람과해맑고 웃으며내게 편지를 쓰나봐오늘 밤도 널 그리워하다못 잊어서 돌아오질 못해이렇게 나는 울었네이별 후 더 힘들다 맘 이젠 추억아직 허기진 조금 남아있우리 다시 만나면감사예전 그대 모습 그대로 일거야안녕다시 또 우리 만날 때까지몇 번이고 말해줘나의 목소리 너의 미소다가올 이별마저 안 될 만큼너를 많이 좋아']"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","source":["### 장르 예측"],"metadata":{"id":"zBnDVupj4xKH"}},{"cell_type":"code","source":["# 한국어 BERT 중 하나인 'klue/bert-base'를 사용.\n","tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"],"metadata":{"id":"MMlK6NiEO5fU","executionInfo":{"status":"ok","timestamp":1696937312525,"user_tz":-540,"elapsed":6,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["num_labels = 14\n","\n","model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\",\n","        num_labels=num_labels, problem_type=\"multi_label_classification\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uX42F3rq4yAp","executionInfo":{"status":"ok","timestamp":1696937315985,"user_tz":-540,"elapsed":3188,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"336b61b0-869f-442f-ba43-3835bfe70a59"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# 모델 로드\n","epoch = 14\n","model.load_state_dict(torch.load(f\"model_bert/BERT_multilabel_model_{epoch}.pt\", map_location=torch.device(\"cpu\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1fC7Wmr5I_g","executionInfo":{"status":"ok","timestamp":1696937320875,"user_tz":-540,"elapsed":4893,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"748c702c-0784-4358-e649-bd1f54ef196c"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["#pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0, max_length=512,\n","#                return_all_scores=True, function_to_apply='sigmoid')\n","\n","pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, max_length=512,\n","                return_all_scores=True, function_to_apply='sigmoid')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ct21JNvn5KUI","executionInfo":{"status":"ok","timestamp":1696937320875,"user_tz":-540,"elapsed":14,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"df20a016-9103-4123-eeb0-0757bcafc80d"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["f = open('model_bert/genre_to_idx.txt', 'r')     # mode = 부분은 생략해도 됨\n","genre_to_idx = f.read()\n","genre_to_idx = eval(genre_to_idx)"],"metadata":{"id":"lHOiJVeZ5P_b","executionInfo":{"status":"ok","timestamp":1696937320875,"user_tz":-540,"elapsed":9,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["for idx, val in enumerate(genre_to_idx):\n","    print(idx, val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iu700HGZ5QPD","executionInfo":{"status":"ok","timestamp":1696937320876,"user_tz":-540,"elapsed":9,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"7e5a584e-9f22-4e1d-8d46-eea0489863d4"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["0 일렉트로니카\n","1 성인가요/트로트\n","2 애니메이션/웹툰\n","3 포크/블루스\n","4 록/메탈\n","5 국내드라마\n","6 인디음악\n","7 만화\n","8 키즈\n","9 랩/힙합\n","10 R&B/Soul\n","11 댄스\n","12 발라드\n","13 국내영화\n"]}]},{"cell_type":"code","source":["label_dict = {f\"LABEL_{idx}\" : val for idx, val  in enumerate(genre_to_idx)}"],"metadata":{"id":"WfI3L8uj5QM7","executionInfo":{"status":"ok","timestamp":1696937320876,"user_tz":-540,"elapsed":8,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["def prediction(text):\n","    result = pipe(text)\n","    return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]"],"metadata":{"id":"ZHIHWgRV5Sg8","executionInfo":{"status":"ok","timestamp":1696937320876,"user_tz":-540,"elapsed":7,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["import re\n","# 가사 전처리\n","def preprocess(sentences):\n","    lst = []\n","    for sentence in sentences:\n","        # \\n과 \\t를 제거한다\n","        sentence = re.sub('\\\\t', '', sentence)\n","        sentence = re.sub('\\\\n', '', sentence)\n","        # 한국어, 공백 빼고 제거하기\n","        sentence = re.sub('[^ㄱ-ㅎ가-힣\\s]+', '', sentence)\n","        # 문장 양옆의 띄어쓰기를 지운다\n","        sentence = sentence.strip()\n","\n","        lst.append(sentence)\n","    return lst"],"metadata":{"id":"A08UQljrNKFU","executionInfo":{"status":"ok","timestamp":1696937320876,"user_tz":-540,"elapsed":6,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["# lyrics_lst : 모델로 생성된 가사\n","\n","lyrics_genre = []\n","\n","for num, lyrics in enumerate(lyrics_lst):\n","  genre = prediction([lyrics])\n","  lyrics_genre.append([lyrics, genre])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GowPnuZl5T6c","executionInfo":{"status":"ok","timestamp":1696937324000,"user_tz":-540,"elapsed":3129,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"4d923392-e576-4b85-b424-c2138042a390"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"code","source":["lyrics_genre"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVO_oYQ9-s03","executionInfo":{"status":"ok","timestamp":1696937324001,"user_tz":-540,"elapsed":10,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"7d489530-0cca-43e9-e940-916ffcc1ee56"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['사랑이별가요 괜찮아 질거야 이별없는 거니까그 많은 약속들은 어제와 같은 선물로점쳐지고 떠나가는 게제 뻔한 일이죠하지만 내 진심만은 알아줬으면 해요한마디 말이면 충분해나 혹시 그대 생각 나겠지만사랑에 바쁜 나를 피해서저별을 준비했단걸사랑이 중요하진 않아잘 안돼 우리가 왜 이렇게 외로운지난 몰라 당신만을 위해서만 기도하고바랬던 사랑이 필요했다면다른 건 아무 의미없어나는 그대를 알기 때문에살아가면서 한번도 느껴지지 않던자존심을 다 버렸',\n","  ['R&B/Soul']],\n"," ['그대 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던 사랑을그대 떠나 가던 밤모두 잊으라시며마지막 인사를 나 하염없이 하던 그 약속간절한 내 마음약속 하지 않았네기다리는 나를 모르시나요행여나 찾아 올까봐 혼자 애태우는 이 마음은어느샌가 거리길가에 스쳐가는언제나 익숙한 목소리작은 두 글자로우리 이름을 써놓고몇 밤을 울다 잠든 다정히 창밖 바라보기만 보며 말하던 나이별을 두고이제는 떠난 사람무엇인가 빈 추억인거죠사랑했던 우리야 이별',\n","  ['성인가요/트로트']],\n"," ['생각도 못했던 말내겐 사랑이란 걸 몰랐던거야이제 우리 같은 시간 속을 남처럼그렇게 걸어왔어요생각보다 오래 된 것 같아요한 번쯤은 나를 떠나줄 것만 같아서난 정말 쉬지 않았죠사랑했던 날 늘 붙잡고떠나지 말라고흘러댔었던 내 맘을하얗게 물들인 밤하늘에 그려보아직도 나는 서 있을까더는 네 모습 볼 수 없겠지만아직 너를 위해 준비해둔 말이제는 말해볼 만하지 못한 나의 마음나는 너무 아파다시 널 보낼 자신이 없어초라했나봐 넌 내게 언제나 이런 얘기를 했었지어',\n","  ['발라드']],\n"," ['사람 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던그 이름 난사랑하네 다정한 그 목소리로노래 불러요잊어 주세요가끔은 그리운 사람과해맑고 웃으며내게 편지를 쓰나봐오늘 밤도 널 그리워하다못 잊어서 돌아오질 못해이렇게 나는 울었네이별 후 더 힘들다 맘 이젠 추억아직 허기진 조금 남아있우리 다시 만나면감사예전 그대 모습 그대로 일거야안녕다시 또 우리 만날 때까지몇 번이고 말해줘나의 목소리 너의 미소다가올 이별마저 안 될 만큼너를 많이 좋아',\n","  ['발라드']]]"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","source":["### 예측한 장르로 곡제목 생성"],"metadata":{"id":"O2pzeSqz5c-m"}},{"cell_type":"code","source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2').to(device)\n","\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8)\n","\n","load_data = torch.load(\"model_kogpt2/genre_song/kogpt2_fine-tunning_13.pt\", map_location=torch.device(\"cpu\"))\n","\n","\n","# 저장한 모델 불러오기\n","# 모델 로드\n","model.load_state_dict(load_data['model'])\n","\n","# 옵티마이저 로드\n","optimizer.load_state_dict(load_data['optimizer'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-kmgwSi5VkD","executionInfo":{"status":"ok","timestamp":1696937352083,"user_tz":-540,"elapsed":13504,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"55737773-7b57-4ade-8fed-a6cb6abbe751"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","                bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","                pad_token='<pad>', mask_token='<mask>')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7p-Iju6l5ViD","executionInfo":{"status":"ok","timestamp":1696937352407,"user_tz":-540,"elapsed":330,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"d02ccf64-0621-4891-dfe0-244929f6de59"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"code","source":["def generate(keyword):\n","    input_ids = tokenizer.encode(keyword, return_tensors='pt')\n","    input_ids = input_ids.to(device)\n","    gen_ids = model.generate(input_ids,\n","                        max_length=128,\n","                        repetition_penalty=2.0,\n","                        pad_token_id=tokenizer.pad_token_id,\n","                        eos_token_id=tokenizer.eos_token_id,\n","                        bos_token_id=tokenizer.bos_token_id,\n","                        use_cache=True)\n","    generated = tokenizer.decode(gen_ids[0])\n","    pad_idx = generated.find('<pad>')\n","    generated = generated[:pad_idx]\n","    return generated"],"metadata":{"id":"lBxBYvUX57XI","executionInfo":{"status":"ok","timestamp":1696937352407,"user_tz":-540,"elapsed":327,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["lyrics_genre[0][1][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4waxvQPGQKRj","executionInfo":{"status":"ok","timestamp":1696937352408,"user_tz":-540,"elapsed":16,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"493ad4a1-002f-4f7d-af3c-a3b053f6ca70"},"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'R&B/Soul'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["genre_lst = [one_row[1][0] for one_row in lyrics_genre]"],"metadata":{"id":"TZ3B6QMZQZkc","executionInfo":{"status":"ok","timestamp":1696937352408,"user_tz":-540,"elapsed":11,"user":{"displayName":"이혜원","userId":"10553305127832445033"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["gen_lst = []\n","for keyword in genre_lst:\n","  gen = generate(keyword)\n","  print(f\"{gen}\")\n","  gen_lst.append(gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYq1B0Dx58tP","executionInfo":{"status":"ok","timestamp":1696937370063,"user_tz":-540,"elapsed":17664,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"e0590390-7c32-4247-d04d-fcf2a00861de"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["R&B/Soul: 너를 그리다\n","성인가요/트로트: 내사랑 그대에게\n","발라드: 사랑합니다...\n","발라드: 사랑합니다...\n"]}]},{"cell_type":"code","source":["gen_lst"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-GC6Hj2QmjM","executionInfo":{"status":"ok","timestamp":1696937370064,"user_tz":-540,"elapsed":11,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"df4475c5-9ac5-4692-8cfb-18de0e97c122"},"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['R&B/Soul: 너를 그리다', '성인가요/트로트: 내사랑 그대에게', '발라드: 사랑합니다...', '발라드: 사랑합니다...']"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["lyrics_genre"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUqnQc7iRvls","executionInfo":{"status":"ok","timestamp":1696937736868,"user_tz":-540,"elapsed":3,"user":{"displayName":"이혜원","userId":"10553305127832445033"}},"outputId":"4ce62aaf-0103-4d43-e009-b4b529961f43"},"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['사랑이별가요 괜찮아 질거야 이별없는 거니까그 많은 약속들은 어제와 같은 선물로점쳐지고 떠나가는 게제 뻔한 일이죠하지만 내 진심만은 알아줬으면 해요한마디 말이면 충분해나 혹시 그대 생각 나겠지만사랑에 바쁜 나를 피해서저별을 준비했단걸사랑이 중요하진 않아잘 안돼 우리가 왜 이렇게 외로운지난 몰라 당신만을 위해서만 기도하고바랬던 사랑이 필요했다면다른 건 아무 의미없어나는 그대를 알기 때문에살아가면서 한번도 느껴지지 않던자존심을 다 버렸',\n","  ['R&B/Soul']],\n"," ['그대 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던 사랑을그대 떠나 가던 밤모두 잊으라시며마지막 인사를 나 하염없이 하던 그 약속간절한 내 마음약속 하지 않았네기다리는 나를 모르시나요행여나 찾아 올까봐 혼자 애태우는 이 마음은어느샌가 거리길가에 스쳐가는언제나 익숙한 목소리작은 두 글자로우리 이름을 써놓고몇 밤을 울다 잠든 다정히 창밖 바라보기만 보며 말하던 나이별을 두고이제는 떠난 사람무엇인가 빈 추억인거죠사랑했던 우리야 이별',\n","  ['성인가요/트로트']],\n"," ['생각도 못했던 말내겐 사랑이란 걸 몰랐던거야이제 우리 같은 시간 속을 남처럼그렇게 걸어왔어요생각보다 오래 된 것 같아요한 번쯤은 나를 떠나줄 것만 같아서난 정말 쉬지 않았죠사랑했던 날 늘 붙잡고떠나지 말라고흘러댔었던 내 맘을하얗게 물들인 밤하늘에 그려보아직도 나는 서 있을까더는 네 모습 볼 수 없겠지만아직 너를 위해 준비해둔 말이제는 말해볼 만하지 못한 나의 마음나는 너무 아파다시 널 보낼 자신이 없어초라했나봐 넌 내게 언제나 이런 얘기를 했었지어',\n","  ['발라드']],\n"," ['사람 사랑했단 거오래 전에 얘기지노을처럼 피어난가슴 태우던그 이름 난사랑하네 다정한 그 목소리로노래 불러요잊어 주세요가끔은 그리운 사람과해맑고 웃으며내게 편지를 쓰나봐오늘 밤도 널 그리워하다못 잊어서 돌아오질 못해이렇게 나는 울었네이별 후 더 힘들다 맘 이젠 추억아직 허기진 조금 남아있우리 다시 만나면감사예전 그대 모습 그대로 일거야안녕다시 또 우리 만날 때까지몇 번이고 말해줘나의 목소리 너의 미소다가올 이별마저 안 될 만큼너를 많이 좋아',\n","  ['발라드']]]"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":[],"metadata":{"id":"mn8Rodj9XvN9"},"execution_count":null,"outputs":[]}]}